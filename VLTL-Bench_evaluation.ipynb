{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38ac147",
   "metadata": {},
   "source": [
    "# VLTL-Bench Evaluation Notebook\n",
    "\n",
    "This notebook evaluates NL-to-LTL translation on the VLTL-Bench datasets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2439595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, pathlib, importlib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# Path where this notebook lives\n",
    "NOTEBOOK_DIR = pathlib.Path.cwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b337618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- User parameters ----\n",
    "DATASET_DIR = pathlib.Path(\"path/to/VLTL_Bench\")\n",
    "\n",
    "# Number of examples to evaluate per dataset\n",
    "N_EXAMPLES   = 500\n",
    "# Frameworks to test\n",
    "FRAMEWORKS   = [\"NL2TL\"]   # \"nl2spec\", \"NL2TL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c1b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 datasets:\n",
      "  - search_and_rescue.jsonl\n",
      "  - traffic_light.jsonl\n",
      "  - warehouse.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Locate dataset files ----\n",
    "if not DATASET_DIR.exists():\n",
    "    raise FileNotFoundError(DATASET_DIR)\n",
    "\n",
    "dataset_files = sorted(p for p in DATASET_DIR.glob(\"*.jsonl\"))\n",
    "print(f\"Found {len(dataset_files)} datasets:\")\n",
    "for p in dataset_files:\n",
    "    print(\"  -\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7627fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>traffic_light</th>\n",
       "      <th>warehouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.652687</td>\n",
       "      <td>0.593536</td>\n",
       "      <td>0.679585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4.1-mini</th>\n",
       "      <td>0.944213</td>\n",
       "      <td>0.966296</td>\n",
       "      <td>0.931708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.667212</td>\n",
       "      <td>0.631292</td>\n",
       "      <td>0.689837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               search_and_rescue  traffic_light  warehouse\n",
       "gpt-3.5-turbo           0.652687       0.593536   0.679585\n",
       "gpt-4.1-mini            0.944213       0.966296   0.931708\n",
       "gpt-4o-mini             0.667212       0.631292   0.689837"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "\n",
    "# Paths (adjust these as needed)\n",
    "eval_root = \"lifting_eval\"\n",
    "test_root = \"VLTL-Bench/test\"\n",
    "\n",
    "# Gather model and dataset names\n",
    "models = sorted([d for d in os.listdir(eval_root) if os.path.isdir(os.path.join(eval_root, d))])\n",
    "datasets = sorted([os.path.splitext(f)[0] for f in os.listdir(test_root) if f.endswith(\".jsonl\")])\n",
    "\n",
    "# Initialize DataFrame for scores\n",
    "sim_df = pd.DataFrame(index=models, columns=datasets, dtype=float)\n",
    "\n",
    "# Compute average for first 500 entries, up to you\n",
    "for model in models:\n",
    "    for ds in datasets:\n",
    "        eval_file = os.path.join(eval_root, model, f\"{ds}.jsonl\")\n",
    "        test_file = os.path.join(test_root, f\"{ds}.jsonl\")\n",
    "        preds, golds = [], []\n",
    "        \n",
    "        # Load predicted lifted sentences\n",
    "        with open(eval_file, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 500: break\n",
    "                data = json.loads(line)\n",
    "                preds.append(\" \".join(data.get(\"grounded_sentence\", [])))\n",
    "        \n",
    "        # Load gold lifted sentences\n",
    "        with open(test_file, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 500: break\n",
    "                data = json.loads(line)\n",
    "                golds.append(\" \".join(data.get(\"lifted_sentence\", [])))\n",
    "        \n",
    "        # Calculate sequence matcher ratio for each pair\n",
    "        ratios = [\n",
    "            difflib.SequenceMatcher(None, p, g).ratio()\n",
    "            for p, g in zip(preds, golds)\n",
    "        ]\n",
    "        \n",
    "        # Store mean ratio\n",
    "        sim_df.at[model, ds] = sum(ratios) / len(ratios) if ratios else None\n",
    "\n",
    "# Display the IoU table\n",
    "display(sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NL2LTL Lifted Translation Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GLTL</th>\n",
       "      <th>cleanup_world</th>\n",
       "      <th>conformal</th>\n",
       "      <th>navi</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>traffic_light</th>\n",
       "      <th>warehouse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_type</th>\n",
       "      <th>trans_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gt_masked_nl</th>\n",
       "      <th>nl2ltl_gpt-3.5-turbo</th>\n",
       "      <td>0.731009</td>\n",
       "      <td>0.753702</td>\n",
       "      <td>0.609977</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.571570</td>\n",
       "      <td>0.539246</td>\n",
       "      <td>0.579585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2ltl_gpt-4.1-mini</th>\n",
       "      <td>0.577988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576665</td>\n",
       "      <td>0.541025</td>\n",
       "      <td>0.449712</td>\n",
       "      <td>0.834634</td>\n",
       "      <td>0.455536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2ltl_gpt-4o-mini</th>\n",
       "      <td>0.791746</td>\n",
       "      <td>0.797404</td>\n",
       "      <td>0.721603</td>\n",
       "      <td>0.648592</td>\n",
       "      <td>0.639463</td>\n",
       "      <td>0.634919</td>\n",
       "      <td>0.611368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llm_masked_nl</th>\n",
       "      <th>nl2ltl_gpt-3.5-turbo</th>\n",
       "      <td>0.298048</td>\n",
       "      <td>0.300768</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.378565</td>\n",
       "      <td>0.690259</td>\n",
       "      <td>0.807079</td>\n",
       "      <td>0.771055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2ltl_gpt-4.1-mini</th>\n",
       "      <td>0.555296</td>\n",
       "      <td>0.633278</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.609555</td>\n",
       "      <td>0.864507</td>\n",
       "      <td>0.864990</td>\n",
       "      <td>0.827534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2ltl_gpt-4o-mini</th>\n",
       "      <td>0.676144</td>\n",
       "      <td>0.688268</td>\n",
       "      <td>0.696453</td>\n",
       "      <td>0.641954</td>\n",
       "      <td>0.691281</td>\n",
       "      <td>0.675532</td>\n",
       "      <td>0.664818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">raw_nl</th>\n",
       "      <th>nl2ltl_gpt-3.5-turbo</th>\n",
       "      <td>0.733297</td>\n",
       "      <td>0.248033</td>\n",
       "      <td>0.383111</td>\n",
       "      <td>0.296605</td>\n",
       "      <td>0.581645</td>\n",
       "      <td>0.525105</td>\n",
       "      <td>0.571979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2ltl_gpt-4.1-mini</th>\n",
       "      <td>0.671283</td>\n",
       "      <td>0.589388</td>\n",
       "      <td>0.595104</td>\n",
       "      <td>0.642422</td>\n",
       "      <td>0.844912</td>\n",
       "      <td>0.836368</td>\n",
       "      <td>0.837575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2ltl_gpt-4o-mini</th>\n",
       "      <td>0.794853</td>\n",
       "      <td>0.796485</td>\n",
       "      <td>0.417352</td>\n",
       "      <td>0.646165</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.637660</td>\n",
       "      <td>0.613745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        GLTL  cleanup_world  conformal  \\\n",
       "eval_type     trans_model                                                \n",
       "gt_masked_nl  nl2ltl_gpt-3.5-turbo  0.731009       0.753702   0.609977   \n",
       "              nl2ltl_gpt-4.1-mini   0.577988            NaN   0.576665   \n",
       "              nl2ltl_gpt-4o-mini    0.791746       0.797404   0.721603   \n",
       "llm_masked_nl nl2ltl_gpt-3.5-turbo  0.298048       0.300768   0.504065   \n",
       "              nl2ltl_gpt-4.1-mini   0.555296       0.633278   0.673554   \n",
       "              nl2ltl_gpt-4o-mini    0.676144       0.688268   0.696453   \n",
       "raw_nl        nl2ltl_gpt-3.5-turbo  0.733297       0.248033   0.383111   \n",
       "              nl2ltl_gpt-4.1-mini   0.671283       0.589388   0.595104   \n",
       "              nl2ltl_gpt-4o-mini    0.794853       0.796485   0.417352   \n",
       "\n",
       "                                        navi  search_and_rescue  \\\n",
       "eval_type     trans_model                                         \n",
       "gt_masked_nl  nl2ltl_gpt-3.5-turbo  0.607692           0.571570   \n",
       "              nl2ltl_gpt-4.1-mini   0.541025           0.449712   \n",
       "              nl2ltl_gpt-4o-mini    0.648592           0.639463   \n",
       "llm_masked_nl nl2ltl_gpt-3.5-turbo  0.378565           0.690259   \n",
       "              nl2ltl_gpt-4.1-mini   0.609555           0.864507   \n",
       "              nl2ltl_gpt-4o-mini    0.641954           0.691281   \n",
       "raw_nl        nl2ltl_gpt-3.5-turbo  0.296605           0.581645   \n",
       "              nl2ltl_gpt-4.1-mini   0.642422           0.844912   \n",
       "              nl2ltl_gpt-4o-mini    0.646165           0.677505   \n",
       "\n",
       "                                    traffic_light  warehouse  \n",
       "eval_type     trans_model                                     \n",
       "gt_masked_nl  nl2ltl_gpt-3.5-turbo       0.539246   0.579585  \n",
       "              nl2ltl_gpt-4.1-mini        0.834634   0.455536  \n",
       "              nl2ltl_gpt-4o-mini         0.634919   0.611368  \n",
       "llm_masked_nl nl2ltl_gpt-3.5-turbo       0.807079   0.771055  \n",
       "              nl2ltl_gpt-4.1-mini        0.864990   0.827534  \n",
       "              nl2ltl_gpt-4o-mini         0.675532   0.664818  \n",
       "raw_nl        nl2ltl_gpt-3.5-turbo       0.525105   0.571979  \n",
       "              nl2ltl_gpt-4.1-mini        0.836368   0.837575  \n",
       "              nl2ltl_gpt-4o-mini         0.637660   0.613745  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NL2SPEC Lifted Translation Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GLTL</th>\n",
       "      <th>cleanup_world</th>\n",
       "      <th>conformal</th>\n",
       "      <th>navi</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>traffic_light</th>\n",
       "      <th>warehouse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_type</th>\n",
       "      <th>trans_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gt_masked_nl</th>\n",
       "      <th>nl2spec_gpt-3.5-turbo</th>\n",
       "      <td>0.203417</td>\n",
       "      <td>0.237886</td>\n",
       "      <td>0.188802</td>\n",
       "      <td>0.345011</td>\n",
       "      <td>0.276003</td>\n",
       "      <td>0.273147</td>\n",
       "      <td>0.280270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2spec_gpt-4.1-mini</th>\n",
       "      <td>0.362687</td>\n",
       "      <td>0.292539</td>\n",
       "      <td>0.393168</td>\n",
       "      <td>0.408544</td>\n",
       "      <td>0.496406</td>\n",
       "      <td>0.501013</td>\n",
       "      <td>0.513144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2spec_gpt-4o-mini</th>\n",
       "      <td>0.370570</td>\n",
       "      <td>0.331770</td>\n",
       "      <td>0.292036</td>\n",
       "      <td>0.286237</td>\n",
       "      <td>0.290943</td>\n",
       "      <td>0.286820</td>\n",
       "      <td>0.278027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llm_masked_nl</th>\n",
       "      <th>nl2spec_gpt-3.5-turbo</th>\n",
       "      <td>0.391836</td>\n",
       "      <td>0.407691</td>\n",
       "      <td>0.270221</td>\n",
       "      <td>0.374474</td>\n",
       "      <td>0.230367</td>\n",
       "      <td>0.205939</td>\n",
       "      <td>0.250685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2spec_gpt-4.1-mini</th>\n",
       "      <td>0.393381</td>\n",
       "      <td>0.396317</td>\n",
       "      <td>0.433627</td>\n",
       "      <td>0.446286</td>\n",
       "      <td>0.504459</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.484946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2spec_gpt-4o-mini</th>\n",
       "      <td>0.423226</td>\n",
       "      <td>0.416372</td>\n",
       "      <td>0.370187</td>\n",
       "      <td>0.396023</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.313839</td>\n",
       "      <td>0.324999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">raw_nl</th>\n",
       "      <th>nl2spec_gpt-3.5-turbo</th>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.314115</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.262233</td>\n",
       "      <td>0.232140</td>\n",
       "      <td>0.256174</td>\n",
       "      <td>0.283846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2spec_gpt-4.1-mini</th>\n",
       "      <td>0.358538</td>\n",
       "      <td>0.291080</td>\n",
       "      <td>0.376967</td>\n",
       "      <td>0.407149</td>\n",
       "      <td>0.496769</td>\n",
       "      <td>0.500626</td>\n",
       "      <td>0.524416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl2spec_gpt-4o-mini</th>\n",
       "      <td>0.369935</td>\n",
       "      <td>0.333859</td>\n",
       "      <td>0.291975</td>\n",
       "      <td>0.286616</td>\n",
       "      <td>0.277219</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>0.277302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         GLTL  cleanup_world  conformal  \\\n",
       "eval_type     trans_model                                                 \n",
       "gt_masked_nl  nl2spec_gpt-3.5-turbo  0.203417       0.237886   0.188802   \n",
       "              nl2spec_gpt-4.1-mini   0.362687       0.292539   0.393168   \n",
       "              nl2spec_gpt-4o-mini    0.370570       0.331770   0.292036   \n",
       "llm_masked_nl nl2spec_gpt-3.5-turbo  0.391836       0.407691   0.270221   \n",
       "              nl2spec_gpt-4.1-mini   0.393381       0.396317   0.433627   \n",
       "              nl2spec_gpt-4o-mini    0.423226       0.416372   0.370187   \n",
       "raw_nl        nl2spec_gpt-3.5-turbo  0.214798       0.314115   0.255639   \n",
       "              nl2spec_gpt-4.1-mini   0.358538       0.291080   0.376967   \n",
       "              nl2spec_gpt-4o-mini    0.369935       0.333859   0.291975   \n",
       "\n",
       "                                         navi  search_and_rescue  \\\n",
       "eval_type     trans_model                                          \n",
       "gt_masked_nl  nl2spec_gpt-3.5-turbo  0.345011           0.276003   \n",
       "              nl2spec_gpt-4.1-mini   0.408544           0.496406   \n",
       "              nl2spec_gpt-4o-mini    0.286237           0.290943   \n",
       "llm_masked_nl nl2spec_gpt-3.5-turbo  0.374474           0.230367   \n",
       "              nl2spec_gpt-4.1-mini   0.446286           0.504459   \n",
       "              nl2spec_gpt-4o-mini    0.396023           0.325893   \n",
       "raw_nl        nl2spec_gpt-3.5-turbo  0.262233           0.232140   \n",
       "              nl2spec_gpt-4.1-mini   0.407149           0.496769   \n",
       "              nl2spec_gpt-4o-mini    0.286616           0.277219   \n",
       "\n",
       "                                     traffic_light  warehouse  \n",
       "eval_type     trans_model                                      \n",
       "gt_masked_nl  nl2spec_gpt-3.5-turbo       0.273147   0.280270  \n",
       "              nl2spec_gpt-4.1-mini        0.501013   0.513144  \n",
       "              nl2spec_gpt-4o-mini         0.286820   0.278027  \n",
       "llm_masked_nl nl2spec_gpt-3.5-turbo       0.205939   0.250685  \n",
       "              nl2spec_gpt-4.1-mini        0.522979   0.484946  \n",
       "              nl2spec_gpt-4o-mini         0.313839   0.324999  \n",
       "raw_nl        nl2spec_gpt-3.5-turbo       0.256174   0.283846  \n",
       "              nl2spec_gpt-4.1-mini        0.500626   0.524416  \n",
       "              nl2spec_gpt-4o-mini         0.272202   0.277302  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from IPython.display import display\n",
    "\n",
    "# ─── ADJUST THIS ──────────────────────────────────────────────────────────────\n",
    "root = \"path/to/translation/eval\"\n",
    "frameworks = [\"nl2ltl\", \"nl2spec\"]\n",
    "max_entries = 500\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "for fw in frameworks:\n",
    "    fw_dir = os.path.join(root, fw)\n",
    "    if not os.path.isdir(fw_dir):\n",
    "        raise FileNotFoundError(f\"Framework folder not found: {fw_dir}\")\n",
    "    \n",
    "    # 1) find eval‐types\n",
    "    eval_types = sorted([\n",
    "        d for d in os.listdir(fw_dir)\n",
    "        if os.path.isdir(os.path.join(fw_dir, d))\n",
    "    ])\n",
    "    \n",
    "    # 2) find translation models under the first eval‐type\n",
    "    first_et = eval_types[0]\n",
    "    sample_et_dir = os.path.join(fw_dir, first_et)\n",
    "    trans_models = sorted([\n",
    "        d for d in os.listdir(sample_et_dir)\n",
    "        if os.path.isdir(os.path.join(sample_et_dir, d))\n",
    "    ])\n",
    "    \n",
    "    # 3) find dataset names from the first translation-model directory\n",
    "    sample_ds_dir = os.path.join(sample_et_dir, trans_models[0])\n",
    "    datasets = sorted([\n",
    "        os.path.splitext(f)[0]\n",
    "        for f in os.listdir(sample_ds_dir)\n",
    "        if f.endswith(\".jsonl\")\n",
    "    ])\n",
    "    \n",
    "    # 4) build MultiIndex and empty DataFrames\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [eval_types, trans_models],\n",
    "        names=[\"eval_type\", \"trans_model\"]\n",
    "    )\n",
    "    acc_df = pd.DataFrame(index=index, columns=datasets, dtype=float)\n",
    "    sim_df = pd.DataFrame(index=index, columns=datasets, dtype=float)\n",
    "    \n",
    "    # 5) fill in metrics\n",
    "    for et in eval_types:\n",
    "        for tm in trans_models:\n",
    "            tm_dir = os.path.join(fw_dir, et, tm)\n",
    "            for ds in datasets:\n",
    "                path = os.path.join(tm_dir, f\"{ds}.jsonl\")\n",
    "                if not os.path.isfile(path):\n",
    "                    continue\n",
    "                preds, targets = [], []\n",
    "                with open(path) as f:\n",
    "                    for i, line in enumerate(f):\n",
    "                        if i >= max_entries:\n",
    "                            break\n",
    "                        ent = json.loads(line)\n",
    "\n",
    "                        if \"masked_tl\" in ent:\n",
    "                            tgt = \" \".join(ent[\"masked_tl\"])\n",
    "                        elif et==\"raw_nl\":\n",
    "                            tgt = \" \".join(ent.get(\"tl\", []))\n",
    "                        pred = ent.get(\"prediction\", \"\").strip()\n",
    "                        # strip leading “1.” or “2.” if present\n",
    "                        parts = pred.split(\" \", 1)\n",
    "                        if parts[0].rstrip(\".\").isdigit() and len(parts) > 1:\n",
    "                            pred = parts[1]\n",
    "                        preds.append(pred)\n",
    "                        targets.append(tgt)\n",
    "                if not targets:\n",
    "                    continue\n",
    "                # binary accuracy\n",
    "                acc_df.at[(et, tm), ds] = sum(p == t for p, t in zip(preds, targets)) / len(targets)\n",
    "                # average sequence‐matching ratio\n",
    "                ratios = [\n",
    "                    difflib.SequenceMatcher(None, p, t).ratio()\n",
    "                    for p, t in zip(preds, targets)\n",
    "                ]\n",
    "                sim_df.at[(et, tm), ds] = sum(ratios) / len(ratios)\n",
    "    \n",
    "    # 6) display\n",
    "    # print(f\"\\n\\n✅ {fw.upper()} Translation — Binary Accuracy\")\n",
    "    # display(acc_df)\n",
    "    print(f\"✅ {fw.upper()} Lifted Translation Accuracy\")\n",
    "    display(sim_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c30ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NL2TL Translation Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLTL</th>\n",
       "      <th>cleanup_world</th>\n",
       "      <th>conformal</th>\n",
       "      <th>navi</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>traffic_light</th>\n",
       "      <th>warehouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert_masked_nl</th>\n",
       "      <td>0.345215</td>\n",
       "      <td>0.313268</td>\n",
       "      <td>0.320866</td>\n",
       "      <td>0.299742</td>\n",
       "      <td>0.375832</td>\n",
       "      <td>0.373162</td>\n",
       "      <td>0.379877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt_lifting</th>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.928629</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_nl</th>\n",
       "      <td>0.717932</td>\n",
       "      <td>0.709023</td>\n",
       "      <td>0.657080</td>\n",
       "      <td>0.642853</td>\n",
       "      <td>0.628225</td>\n",
       "      <td>0.586153</td>\n",
       "      <td>0.655364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GLTL  cleanup_world  conformal      navi  \\\n",
       "bert_masked_nl  0.345215       0.313268   0.320866  0.299742   \n",
       "gt_lifting      0.998685       0.999563   0.928629  0.997828   \n",
       "raw_nl          0.717932       0.709023   0.657080  0.642853   \n",
       "\n",
       "                search_and_rescue  traffic_light  warehouse  \n",
       "bert_masked_nl           0.375832       0.373162   0.379877  \n",
       "gt_lifting               1.000000       1.000000   1.000000  \n",
       "raw_nl                   0.628225       0.586153   0.655364  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from IPython.display import display\n",
    "\n",
    "# ─── CONFIG ──────────────────────────────────────────────────────────────\n",
    "root = \"path/to/nl2tl eval\"\n",
    "eval_types = [\"LLM_masked_nl\", \"gt_lifting\", \"raw_nl\"]\n",
    "max_entries = 500\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# discover dataset names from the first eval_type\n",
    "datasets = sorted([\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(os.path.join(root, eval_types[0]))\n",
    "    if f.endswith(\".jsonl\")\n",
    "])\n",
    "\n",
    "# initialize DataFrames\n",
    "acc_df = pd.DataFrame(index=eval_types, columns=datasets, dtype=float)\n",
    "sim_df = pd.DataFrame(index=eval_types, columns=datasets, dtype=float)\n",
    "\n",
    "def best_substring_similarity(prediction: str, target: str) -> float:\n",
    "    \"\"\"\n",
    "    Return the highest SequenceMatcher ratio between `target`\n",
    "    and any substring of `prediction` of length len(target).\n",
    "    If prediction is shorter than target, compare whole strings.\n",
    "    \"\"\"\n",
    "    sm = difflib.SequenceMatcher\n",
    "    t_len, p_len = len(target), len(prediction)\n",
    "    if p_len < t_len:\n",
    "        return sm(None, prediction, target).ratio()\n",
    "    best = 0.0\n",
    "    for i in range(p_len - t_len + 1):\n",
    "        sub = prediction[i : i + t_len]\n",
    "        best = max(best, sm(None, sub, target).ratio())\n",
    "    return best\n",
    "\n",
    "# compute metrics\n",
    "for et in eval_types:\n",
    "    et_dir = os.path.join(root, et)\n",
    "    for ds in datasets:\n",
    "        file_path = os.path.join(et_dir, f\"{ds}.jsonl\")\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        preds, targets = [], []\n",
    "        with open(file_path) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= max_entries:\n",
    "                    break\n",
    "                ent = json.loads(line)\n",
    "                # target = grounded_sentence if present, else raw sentence\n",
    "                if \"masked_tl\" in ent:\n",
    "                    tgt = \" \".join(ent[\"masked_tl\"])\n",
    "                elif et==\"raw_nl\":\n",
    "                    tgt = \" \".join(ent.get(\"tl\", []))\n",
    "                # clean prediction\n",
    "                pred = ent.get(\"prediction\", \"\").strip()\n",
    "                parts = pred.split(\" \", 1)\n",
    "                if parts[0].rstrip(\".\").isdigit() and len(parts) > 1:\n",
    "                    pred = parts[1]\n",
    "                preds.append(pred)\n",
    "                targets.append(tgt)\n",
    "\n",
    "        if not targets:\n",
    "            continue\n",
    "\n",
    "        # binary accuracy\n",
    "        acc_df.at[et, ds] = sum(p == t for p, t in zip(preds, targets)) / len(targets)\n",
    "        # substring-based similarity\n",
    "        sim_df.at[et, ds] = sum(\n",
    "            best_substring_similarity(p, t)\n",
    "            for p, t in zip(preds, targets)\n",
    "        ) / len(targets)\n",
    "\n",
    "\n",
    "print(\"✅ NL2TL Translation Accuracy\")\n",
    "display(sim_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a699ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2ltl_gpt-4.1-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nl2ltl/gt_masked_nl/nl2ltl_gpt-4.1-mini/search_and_rescue: 500it [00:00, 28858.96it/s]\n",
      "nl2ltl/gt_masked_nl/nl2ltl_gpt-4.1-mini/traffic_light: 500it [00:00, 35161.16it/s]\n",
      "nl2ltl/gt_masked_nl/nl2ltl_gpt-4.1-mini/warehouse: 500it [00:00, 32273.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2ltl_gpt-4.1-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nl2ltl/raw_nl/nl2ltl_gpt-4.1-mini/search_and_rescue: 500it [00:00, 41596.95it/s]\n",
      "nl2ltl/raw_nl/nl2ltl_gpt-4.1-mini/traffic_light: 500it [00:00, 44155.22it/s]\n",
      "nl2ltl/raw_nl/nl2ltl_gpt-4.1-mini/warehouse: 500it [00:00, 43201.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2ltl_gpt-4.1-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nl2ltl/llm_masked_nl/nl2ltl_gpt-4.1-mini/search_and_rescue: 500it [00:00, 33527.07it/s]\n",
      "nl2ltl/llm_masked_nl/nl2ltl_gpt-4.1-mini/traffic_light: 500it [00:00, 39667.70it/s]\n",
      "nl2ltl/llm_masked_nl/nl2ltl_gpt-4.1-mini/warehouse: 500it [00:00, 41457.16it/s]\n",
      "nl2tl/raw_nl/search_and_rescue: 500it [00:00, 25163.51it/s]\n",
      "nl2tl/raw_nl/traffic_light: 500it [00:00, 26138.92it/s]\n",
      "nl2tl/raw_nl/warehouse: 500it [00:00, 24994.06it/s]\n",
      "nl2tl/gt_lifting/search_and_rescue: 500it [00:00, 44330.69it/s]\n",
      "nl2tl/gt_lifting/traffic_light: 500it [00:00, 52791.74it/s]\n",
      "nl2tl/gt_lifting/warehouse: 500it [00:00, 46853.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2spec_gpt-4.1-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nl2spec/gt_masked_nl/nl2spec_gpt-4.1-mini/search_and_rescue: 500it [00:00, 17978.77it/s]\n",
      "nl2spec/gt_masked_nl/nl2spec_gpt-4.1-mini/traffic_light: 500it [00:00, 21163.05it/s]\n",
      "nl2spec/gt_masked_nl/nl2spec_gpt-4.1-mini/warehouse: 500it [00:00, 23947.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2spec_gpt-4.1-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nl2spec/raw_nl/nl2spec_gpt-4.1-mini/search_and_rescue: 500it [00:00, 22009.26it/s]\n",
      "nl2spec/raw_nl/nl2spec_gpt-4.1-mini/traffic_light: 500it [00:00, 22718.58it/s]\n",
      "nl2spec/raw_nl/nl2spec_gpt-4.1-mini/warehouse: 500it [00:00, 25197.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl2spec_gpt-4.1-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nl2spec/llm_masked_nl/nl2spec_gpt-4.1-mini/search_and_rescue: 500it [00:00, 25899.08it/s]\n",
      "nl2spec/llm_masked_nl/nl2spec_gpt-4.1-mini/traffic_light: 500it [00:00, 28145.91it/s]\n",
      "nl2spec/llm_masked_nl/nl2spec_gpt-4.1-mini/warehouse: 500it [00:00, 27425.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework</th>\n",
       "      <th>lifting</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>total</th>\n",
       "      <th>ok_good(%)</th>\n",
       "      <th>ok_bad(%)</th>\n",
       "      <th>ok_both(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>gt_masked_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>gt_masked_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>gt_masked_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>llm_masked_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>llm_masked_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nl2ltl</td>\n",
       "      <td>llm_masked_nl</td>\n",
       "      <td>nl2ltl_gpt-4.1-mini</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nl2tl</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2ltl_gpt-3.5-turbo</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nl2tl</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2ltl_gpt-3.5-turbo</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nl2tl</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2ltl_gpt-3.5-turbo</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nl2tl</td>\n",
       "      <td>gt_lifting</td>\n",
       "      <td>nl2ltl_gpt-3.5-turbo</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nl2tl</td>\n",
       "      <td>gt_lifting</td>\n",
       "      <td>nl2ltl_gpt-3.5-turbo</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nl2tl</td>\n",
       "      <td>gt_lifting</td>\n",
       "      <td>nl2ltl_gpt-3.5-turbo</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>gt_masked_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>gt_masked_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>gt_masked_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>raw_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>llm_masked_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>500</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>llm_masked_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>500</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nl2spec</td>\n",
       "      <td>llm_masked_nl</td>\n",
       "      <td>nl2spec_gpt-4.1-mini</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>500</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   framework        lifting                 model            dataset  total  \\\n",
       "0     nl2ltl   gt_masked_nl   nl2ltl_gpt-4.1-mini  search_and_rescue    500   \n",
       "1     nl2ltl   gt_masked_nl   nl2ltl_gpt-4.1-mini      traffic_light    500   \n",
       "2     nl2ltl   gt_masked_nl   nl2ltl_gpt-4.1-mini          warehouse    500   \n",
       "3     nl2ltl         raw_nl   nl2ltl_gpt-4.1-mini  search_and_rescue    500   \n",
       "4     nl2ltl         raw_nl   nl2ltl_gpt-4.1-mini      traffic_light    500   \n",
       "5     nl2ltl         raw_nl   nl2ltl_gpt-4.1-mini          warehouse    500   \n",
       "6     nl2ltl  llm_masked_nl   nl2ltl_gpt-4.1-mini  search_and_rescue    500   \n",
       "7     nl2ltl  llm_masked_nl   nl2ltl_gpt-4.1-mini      traffic_light    500   \n",
       "8     nl2ltl  llm_masked_nl   nl2ltl_gpt-4.1-mini          warehouse    500   \n",
       "9      nl2tl         raw_nl  nl2ltl_gpt-3.5-turbo  search_and_rescue    500   \n",
       "10     nl2tl         raw_nl  nl2ltl_gpt-3.5-turbo      traffic_light    500   \n",
       "11     nl2tl         raw_nl  nl2ltl_gpt-3.5-turbo          warehouse    500   \n",
       "12     nl2tl     gt_lifting  nl2ltl_gpt-3.5-turbo  search_and_rescue    500   \n",
       "13     nl2tl     gt_lifting  nl2ltl_gpt-3.5-turbo      traffic_light    500   \n",
       "14     nl2tl     gt_lifting  nl2ltl_gpt-3.5-turbo          warehouse    500   \n",
       "15   nl2spec   gt_masked_nl  nl2spec_gpt-4.1-mini  search_and_rescue    500   \n",
       "16   nl2spec   gt_masked_nl  nl2spec_gpt-4.1-mini      traffic_light    500   \n",
       "17   nl2spec   gt_masked_nl  nl2spec_gpt-4.1-mini          warehouse    500   \n",
       "18   nl2spec         raw_nl  nl2spec_gpt-4.1-mini  search_and_rescue    500   \n",
       "19   nl2spec         raw_nl  nl2spec_gpt-4.1-mini      traffic_light    500   \n",
       "20   nl2spec         raw_nl  nl2spec_gpt-4.1-mini          warehouse    500   \n",
       "21   nl2spec  llm_masked_nl  nl2spec_gpt-4.1-mini  search_and_rescue    500   \n",
       "22   nl2spec  llm_masked_nl  nl2spec_gpt-4.1-mini      traffic_light    500   \n",
       "23   nl2spec  llm_masked_nl  nl2spec_gpt-4.1-mini          warehouse    500   \n",
       "\n",
       "    ok_good(%)  ok_bad(%)  ok_both(%)  \n",
       "0        0.106      0.320       0.074  \n",
       "1        0.618      0.592       0.366  \n",
       "2        0.124      0.362       0.098  \n",
       "3        0.616      0.614       0.354  \n",
       "4        0.646      0.602       0.384  \n",
       "5        0.524      0.586       0.262  \n",
       "6        0.496      0.588       0.318  \n",
       "7        0.532      0.598       0.362  \n",
       "8        0.448      0.566       0.264  \n",
       "9        0.114      0.114       0.114  \n",
       "10       0.078      0.078       0.078  \n",
       "11       0.142      0.142       0.142  \n",
       "12       0.750      0.794       0.544  \n",
       "13       0.802      0.806       0.608  \n",
       "14       0.714      0.748       0.462  \n",
       "15       0.260      0.290       0.160  \n",
       "16       0.328      0.320       0.228  \n",
       "17       0.286      0.322       0.170  \n",
       "18       0.244      0.268       0.136  \n",
       "19       0.310      0.286       0.206  \n",
       "20       0.314      0.346       0.196  \n",
       "21       0.340      0.364       0.210  \n",
       "22       0.402      0.418       0.282  \n",
       "23       0.320      0.346       0.190  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jupyter notebook cell: Verification evaluation with parser-error handling\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Union\n",
    "from tqdm import tqdm\n",
    "from functools import lru_cache\n",
    "from pyModelChecking.LTL import Parser, AtomicProposition as AP, Not, And, Or, Imply, X, F, G, U\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1 — Normalisation / implication elimination\n",
    "# ----------------------------------------------------------------------------\n",
    "TOKEN_MAP = {\n",
    "    \"globally\": \"G\", \"always\": \"G\", \"[]\": \"G\",\n",
    "    \"finally\": \"F\", \"eventually\": \"F\", \"<>\": \"F\",\n",
    "    \"next\": \"X\", \"until\": \"U\",\n",
    "    \"not\": \"not\", \"¬\": \"not\", \"!\": \"not\", \n",
    "    \"&\": \"and\", \"∧\": \"and\",\n",
    "    \"|\": \"or\", \"∨\": \"or\", \"or\": \"or\",\n",
    "    \"imply\": \"-->\", \"implies\": \"-->\", \"->\": \"-->\",\n",
    "    \"⇒\": \"-->\",\n",
    "    \"double_implies\": \"-->\"\n",
    "}\n",
    "_PARSER = Parser()\n",
    "_AP_OK = re.compile(r\"^[A-Za-z_][A-Za-z0-9_]*$\")\n",
    "\n",
    "def _normalise_tokens(tokens: List[str]) -> str:\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        low = t.lower()\n",
    "        if low in TOKEN_MAP:\n",
    "            out.append(TOKEN_MAP[low])\n",
    "        elif t in (\"(\", \")\"):\n",
    "            out.append(t)\n",
    "        elif _AP_OK.match(t):\n",
    "            out.append(t)\n",
    "        else:\n",
    "            out.append(f\"'{t}'\")\n",
    "    return \" \".join(out)\n",
    "\n",
    "def _elim_impl_tokens(tokens: List[str]) -> List[str]:\n",
    "    while True:\n",
    "        depth = [0] * len(tokens)\n",
    "        d = 0\n",
    "        for i, tok in enumerate(tokens):\n",
    "            if tok == \"(\":\n",
    "                d += 1\n",
    "            depth[i] = d\n",
    "            if tok == \")\":\n",
    "                d -= 1\n",
    "        for i, tok in enumerate(tokens):\n",
    "            if tok not in (\"->\", \"-->\"):\n",
    "                continue\n",
    "            di = depth[i]\n",
    "            j = i - 1\n",
    "            while j >= 0 and depth[j] >= di:\n",
    "                j -= 1\n",
    "            lhs_start = j + 1\n",
    "            k = i + 1\n",
    "            while k < len(tokens) and depth[k] >= di:\n",
    "                k += 1\n",
    "            rhs_end = k\n",
    "            lhs = tokens[lhs_start:i]\n",
    "            rhs = tokens[i+1:rhs_end]\n",
    "            new = [\"(\", \"(\", \"not\"] + lhs + [\")\", \"or\", \"(\"] + rhs + [\")\", \")\"]\n",
    "            tokens = tokens[:lhs_start] + new + tokens[rhs_end:]\n",
    "            break\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "@lru_cache(maxsize=16384)\n",
    "def _parse(formula_str: str):\n",
    "    return _PARSER(formula_str)\n",
    "\n",
    "def _eval(ast, trace: List[Set[str]], t: int = 0) -> bool:\n",
    "    if isinstance(ast, AP):\n",
    "        return str(ast) in trace[t]\n",
    "    if isinstance(ast, Not):\n",
    "        return not _eval(ast.subformula(0), trace, t)\n",
    "    if isinstance(ast, And):\n",
    "        return _eval(ast.subformula(0), trace, t) and _eval(ast.subformula(1), trace, t)\n",
    "    if isinstance(ast, Or):\n",
    "        return _eval(ast.subformula(0), trace, t) or _eval(ast.subformula(1), trace, t)\n",
    "    if isinstance(ast, Imply):\n",
    "        return (not _eval(ast.subformula(0), trace, t)) or _eval(ast.subformula(1), trace, t)\n",
    "    if isinstance(ast, X):\n",
    "        return _eval(ast.subformula(0), trace, min(t+1, len(trace)-1))\n",
    "    if isinstance(ast, F):\n",
    "        return any(_eval(ast.subformula(0), trace, k) for k in range(t, len(trace)))\n",
    "    if isinstance(ast, G):\n",
    "        return all(_eval(ast.subformula(0), trace, k) for k in range(t, len(trace)))\n",
    "    if isinstance(ast, U):\n",
    "        φ, ψ = ast.subformula(0), ast.subformula(1)\n",
    "        for k in range(t, len(trace)):\n",
    "            if _eval(ψ, trace, k):\n",
    "                return all(_eval(φ, trace, j) for j in range(t, k))\n",
    "        return False\n",
    "    raise NotImplementedError(f\"Unsupported AST node: {type(ast)}\")\n",
    "\n",
    "def _tokenise(tokens: Union[List[str], str]) -> List[str]:\n",
    "    if isinstance(tokens, str):\n",
    "        return re.findall(r\"\\w+|[()]\", tokens)\n",
    "    return tokens\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2 — Load ground-truth test entries\n",
    "# ----------------------------------------------------------------------------\n",
    "test_set_dir = Path(\"VLTL-Bench/test\")\n",
    "datasets = [\"search_and_rescue\", \"traffic_light\", \"warehouse\"]\n",
    "test_entries = {}\n",
    "for ds in datasets:\n",
    "    m = {}\n",
    "    with open(test_set_dir/f\"{ds}.jsonl\") as f:\n",
    "        for line in f:\n",
    "            e = json.loads(line)\n",
    "            m[e[\"id\"]] = e\n",
    "    test_entries[ds] = m\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3 — Run evaluation with parser-error handling\n",
    "# ----------------------------------------------------------------------------\n",
    "base_eval_dir = Path(\"translation_eval\")\n",
    "results = []\n",
    "\n",
    "for fw_dir in base_eval_dir.iterdir():\n",
    "    if not fw_dir.is_dir(): \n",
    "        continue\n",
    "    framework = fw_dir.name\n",
    "\n",
    "    # nl2tl structure\n",
    "    if framework == \"nl2tl\":\n",
    "        # continue\n",
    "        for lift_dir in fw_dir.iterdir():\n",
    "            lifting = lift_dir.name\n",
    "            for ds in datasets:\n",
    "                file = lift_dir/f\"{ds}.jsonl\"\n",
    "                if not file.exists():\n",
    "                    continue\n",
    "                total = ok_good = ok_bad = ok_both = 0\n",
    "                for line in tqdm(file.open(), desc=f\"{framework}/{lifting}/{ds}\"):\n",
    "                    e = json.loads(line)\n",
    "                    gt = test_entries[ds][e[\"id\"]]\n",
    "                    mapping = {\n",
    "                        pid: f\"{info['action_canon']}({','.join(info.get('args_canon',[]))})\"\n",
    "                        for pid,info in gt[\"prop_dict\"].items()\n",
    "                    }\n",
    "                    rev = {v:k for k,v in mapping.items()}\n",
    "                    to_labels = lambda raw: [{rev.get(ap,ap) for ap in step} for step in raw]\n",
    "                    good, bad = to_labels(gt[\"good_trace\"]), to_labels(gt[\"bad_trace\"])\n",
    "                    phi = e[\"prediction\"]\n",
    "                    if type(phi) == List: phi = \"\".join(phi)\n",
    "                    \n",
    "\n",
    "                    # ---- build a clean LTL string ----\n",
    "                    tokens   = _tokenise(phi)                    # list of word‐tokens\n",
    "                    norm_str  = _normalise_tokens(tokens)        # e.g. \"globally ( prop_1 implies … )\"\n",
    "                    toks      = norm_str.split()                 # back to list\n",
    "                    elim      = _elim_impl_tokens(toks)          # impl‐elim\n",
    "                    f_str     = \" \".join(elim)                   # final formula string\n",
    "                    try:\n",
    "                        ast       = _parse(f_str)                    # parse AST\n",
    "                                                # ---- evaluate ----\n",
    "                        good_sat = _eval(ast, good)\n",
    "                        bad_sat  = _eval(ast, bad)\n",
    "\n",
    "                        if good_sat:\n",
    "                            ok_good += 1\n",
    "                        if not bad_sat:\n",
    "                            ok_bad += 1\n",
    "                        if good_sat and not bad_sat:\n",
    "                            ok_both += 1\n",
    "                    except Exception:\n",
    "                        bad_parse +=1 \n",
    "\n",
    "                    total += 1\n",
    "                    # print(bad_parse)\n",
    "                results.append((\n",
    "                    framework, lifting, model, ds, total,\n",
    "                    ok_good/total, ok_bad/total, ok_both/total\n",
    "                ))\n",
    "\n",
    "    else:\n",
    "        for lift_dir in fw_dir.iterdir():\n",
    "            lifting = lift_dir.name\n",
    "            for model_dir in lift_dir.iterdir():\n",
    "                model = model_dir.name\n",
    "                if '4.1-mini' not in model:\n",
    "                    continue\n",
    "                print(model)\n",
    "                for ds in datasets:\n",
    "                    file = model_dir / f\"{ds}.jsonl\"\n",
    "                    if not file.exists():\n",
    "                        continue\n",
    "\n",
    "                    total = ok_good = ok_bad = ok_both = bad_parse = 0\n",
    "                    for line in tqdm(file.open(), desc=f\"{framework}/{lifting}/{model}/{ds}\"):\n",
    "                        e = json.loads(line)\n",
    "                        gt = test_entries[ds][e[\"id\"]]\n",
    "\n",
    "                        # rebuild prop->atom mapping\n",
    "                        mapping = {\n",
    "                            pid: f\"{info['action_canon']}({','.join(info.get('args_canon', []))})\"\n",
    "                            for pid, info in gt[\"prop_dict\"].items()\n",
    "                        }\n",
    "                        rev_map = {atom: pid for pid, atom in mapping.items()}\n",
    "                        to_labels = lambda raw: [{rev_map.get(ap, ap) for ap in step} for step in raw]\n",
    "                        good, bad = to_labels(gt[\"good_trace\"]), to_labels(gt[\"bad_trace\"])\n",
    "\n",
    "                        # strip any ChatGPT prefixes/suffixes\n",
    "                        phi = e[\"prediction\"]\n",
    "                        if phi.startswith('LTL:'):\n",
    "                            phi = phi[4:]\n",
    "                        if phi.startswith('3. *FINAL:* '):\n",
    "                            phi = phi[12:]\n",
    "                        for suffix in ('*FINISH*', 'FINISH'):\n",
    "                            if phi.endswith(suffix):\n",
    "                                phi = phi[: -len(suffix)]\n",
    "\n",
    "                        # ---- build a clean LTL string ----\n",
    "                        tokens   = _tokenise(phi)                    # list of word‐tokens\n",
    "                        norm_str  = _normalise_tokens(tokens)        # e.g. \"globally ( prop_1 implies … )\"\n",
    "                        toks      = norm_str.split()                 # back to list\n",
    "                        elim      = _elim_impl_tokens(toks)          # impl‐elim\n",
    "                        f_str     = \" \".join(elim)                   # final formula string\n",
    "                        try:\n",
    "                            ast       = _parse(f_str)                    # parse AST\n",
    "                                                    # ---- evaluate ----\n",
    "                            good_sat = _eval(ast, good)\n",
    "                            bad_sat  = _eval(ast, bad)\n",
    "\n",
    "                            if good_sat:\n",
    "                                ok_good += 1\n",
    "                            if not bad_sat:\n",
    "                                ok_bad += 1\n",
    "                            if good_sat and not bad_sat:\n",
    "                                ok_both += 1\n",
    "                        except Exception:\n",
    "                            bad_parse +=1 \n",
    "\n",
    "                        total += 1\n",
    "                        # print(bad_parse)\n",
    "                    results.append((\n",
    "                        framework, lifting, model, ds, total,\n",
    "                        ok_good/total, ok_bad/total, ok_both/total\n",
    "                    ))\n",
    "\n",
    "\n",
    "                        # results.append((framework, lifting, model, ds, total,\n",
    "                        #                 ok_good/total, ok_bad/total, ok_both/total))\n",
    "\n",
    "# Summarize\n",
    "columns = [\"framework\",\"lifting\",\"model\",\"dataset\",\"total\",\n",
    "           \"ok_good(%)\",\"ok_bad(%)\",\"ok_both(%)\"]\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2bab44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings 'apple' and 'aplle' are similar: True\n",
      "Strings 'banana' and 'bananas' are similar: True\n",
      "Strings 'grape' and 'fruit' are similar: False\n"
     ]
    }
   ],
   "source": [
    "def are_strings_similar(str1, str2, max_diff):\n",
    "    \"\"\"\n",
    "    Checks if two strings are the same within a maximum difference \n",
    "    in the number of characters.\n",
    "\n",
    "    Args:\n",
    "        str1: The first string.\n",
    "        str2: The second string.\n",
    "        max_diff: The maximum allowed difference in characters.\n",
    "\n",
    "    Returns:\n",
    "        True if the strings are similar within the max_diff, False otherwise.\n",
    "    \"\"\"\n",
    "    if abs(len(str1) - len(str2)) > max_diff:\n",
    "        return False\n",
    "\n",
    "    diff_count = 0\n",
    "    min_len = min(len(str1), len(str2))\n",
    "\n",
    "    for i in range(min_len):\n",
    "        if str1[i] != str2[i]:\n",
    "            diff_count += 1\n",
    "    \n",
    "    diff_count += abs(len(str1) - len(str2))\n",
    "\n",
    "    return diff_count <= max_diff\n",
    "\n",
    "# Example usage\n",
    "string1 = \"apple\"\n",
    "string2 = \"aplle\"\n",
    "max_difference = 1\n",
    "result = are_strings_similar(string1, string2, max_difference)\n",
    "print(f\"Strings '{string1}' and '{string2}' are similar: {result}\")\n",
    "\n",
    "string3 = \"banana\"\n",
    "string4 = \"bananas\"\n",
    "max_difference = 1\n",
    "result = are_strings_similar(string3, string4, max_difference)\n",
    "print(f\"Strings '{string3}' and '{string4}' are similar: {result}\")\n",
    "\n",
    "string5 = \"grape\"\n",
    "string6 = \"fruit\"\n",
    "max_difference = 2\n",
    "result = are_strings_similar(string5, string6, max_difference)\n",
    "print(f\"Strings '{string5}' and '{string6}' are similar: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa45009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>dataset</th>\n",
       "      <th>exact_match_accuracy</th>\n",
       "      <th>prop_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_5_turbo</td>\n",
       "      <td>base</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.569524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3_5_turbo</td>\n",
       "      <td>base</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.695441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_5_turbo</td>\n",
       "      <td>base</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.182785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_5_turbo</td>\n",
       "      <td>scenario</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_5_turbo</td>\n",
       "      <td>scenario</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.372454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3_5_turbo</td>\n",
       "      <td>scenario</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4_1_mini</td>\n",
       "      <td>base</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4_1_mini</td>\n",
       "      <td>base</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.674103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4_1_mini</td>\n",
       "      <td>base</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.237911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4_1_mini</td>\n",
       "      <td>scenario</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4_1_mini</td>\n",
       "      <td>scenario</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.279340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4_1_mini</td>\n",
       "      <td>scenario</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.344294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4o_mini</td>\n",
       "      <td>base</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.822857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4o_mini</td>\n",
       "      <td>base</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.665373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4o_mini</td>\n",
       "      <td>base</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.183752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4o_mini</td>\n",
       "      <td>scenario</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.667619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4o_mini</td>\n",
       "      <td>scenario</td>\n",
       "      <td>traffic_light</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.168768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4o_mini</td>\n",
       "      <td>scenario</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.235977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model    prompt            dataset  exact_match_accuracy  \\\n",
       "0   3_5_turbo      base  search_and_rescue                 0.342   \n",
       "1   3_5_turbo      base      traffic_light                 0.514   \n",
       "2   3_5_turbo      base          warehouse                 0.074   \n",
       "3   3_5_turbo  scenario  search_and_rescue                 0.636   \n",
       "4   3_5_turbo  scenario      traffic_light                 0.208   \n",
       "5   3_5_turbo  scenario          warehouse                 0.050   \n",
       "6    4_1_mini      base  search_and_rescue                 0.604   \n",
       "7    4_1_mini      base      traffic_light                 0.458   \n",
       "8    4_1_mini      base          warehouse                 0.078   \n",
       "9    4_1_mini  scenario  search_and_rescue                 0.452   \n",
       "10   4_1_mini  scenario      traffic_light                 0.154   \n",
       "11   4_1_mini  scenario          warehouse                 0.130   \n",
       "12    4o_mini      base  search_and_rescue                 0.686   \n",
       "13    4o_mini      base      traffic_light                 0.484   \n",
       "14    4o_mini      base          warehouse                 0.070   \n",
       "15    4o_mini  scenario  search_and_rescue                 0.448   \n",
       "16    4o_mini  scenario      traffic_light                 0.074   \n",
       "17    4o_mini  scenario          warehouse                 0.092   \n",
       "\n",
       "    prop_accuracy  \n",
       "0        0.569524  \n",
       "1        0.695441  \n",
       "2        0.182785  \n",
       "3        0.766667  \n",
       "4        0.372454  \n",
       "5        0.136364  \n",
       "6        0.773333  \n",
       "7        0.674103  \n",
       "8        0.237911  \n",
       "9        0.686667  \n",
       "10       0.279340  \n",
       "11       0.344294  \n",
       "12       0.822857  \n",
       "13       0.665373  \n",
       "14       0.183752  \n",
       "15       0.667619  \n",
       "16       0.168768  \n",
       "17       0.235977  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jupyter evaluation segment: exact‐match and prop‐level accuracy with fence‐stripping\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Adjust these paths if needed\n",
    "RESULTS_DIR = Path(\"grounding_eval\")\n",
    "TEST_DIR    = Path(\"VLTL-Bench/test\")\n",
    "\n",
    "# 1. Load ground‑truth prop_dicts\n",
    "test_data = {}\n",
    "for ds_file in TEST_DIR.glob(\"*.jsonl\"):\n",
    "    ds_name = ds_file.stem\n",
    "    entries = [json.loads(line) for line in ds_file.open(\"r\")]\n",
    "    test_data[ds_name] = {entry[\"id\"]: entry[\"prop_dict\"] for entry in entries}\n",
    "\n",
    "# 2. Parse model outputs and strip code fences\n",
    "records = []\n",
    "for model_dir in RESULTS_DIR.iterdir():\n",
    "    if not model_dir.is_dir():\n",
    "        continue\n",
    "    model_name = model_dir.name\n",
    "    for result_file in model_dir.glob(\"*.jsonl\"):\n",
    "        stem = result_file.stem              # e.g. \"search_and_rescue_base\"\n",
    "        dataset, prompt_type = stem.rsplit(\"_\", 1)\n",
    "        responses = [json.loads(line) for line in result_file.open(\"r\")]\n",
    "\n",
    "        for resp in responses:\n",
    "            # extract test-entry ID from custom_id: \"dataset-model-entryid\"\n",
    "            cid = resp[\"custom_id\"]\n",
    "            entry_id = int(cid.split(\"-\")[-1])\n",
    "\n",
    "            # raw assistant content\n",
    "            raw = resp[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "            # strip fences and prefixes\n",
    "            clean = raw.strip()\n",
    "            if clean.startswith(\"```\"):\n",
    "                lines = clean.splitlines()\n",
    "                # drop leading fence line\n",
    "                lines = lines[1:]\n",
    "                # drop trailing fence if present\n",
    "                if lines and lines[-1].strip().startswith(\"```\"):\n",
    "                    lines = lines[:-1]\n",
    "                clean = \"\\n\".join(lines)\n",
    "            # remove any \"prop_dict:\" prefix before JSON\n",
    "            if clean.lstrip().startswith(\"prop_dict\"):\n",
    "                idx = clean.find(\"{\")\n",
    "                clean = clean[idx:]\n",
    "\n",
    "            # parse JSON\n",
    "            try:\n",
    "                pred_dict = json.loads(clean)\n",
    "            except json.JSONDecodeError:\n",
    "                pred_dict = None\n",
    "\n",
    "            # ground truth\n",
    "            gt_dict = test_data.get(dataset, {}).get(entry_id, {})\n",
    "\n",
    "            # exact‐match?\n",
    "            exact = (pred_dict == gt_dict)\n",
    "\n",
    "            # prop‐level correctness\n",
    "            total_props   = len(gt_dict)\n",
    "            correct_props = 0\n",
    "            if isinstance(pred_dict, dict):\n",
    "                for key, val in gt_dict.items():\n",
    "                    if pred_dict.get(key) == val:\n",
    "                        correct_props += 1\n",
    "\n",
    "            records.append({\n",
    "                \"model\":         model_name,\n",
    "                \"dataset\":       dataset,\n",
    "                \"prompt\":        prompt_type,\n",
    "                \"id\":            entry_id,\n",
    "                \"exact_match\":   exact,\n",
    "                \"correct_props\": correct_props,\n",
    "                \"total_props\":   total_props\n",
    "            })\n",
    "\n",
    "# 3. Build DataFrame and compute accuracies\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# a) Entry‐level exact match accuracy\n",
    "exact_acc = (\n",
    "    df\n",
    "    .groupby([\"model\", \"prompt\", \"dataset\"])[\"exact_match\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"exact_match\": \"exact_match_accuracy\"})\n",
    ")\n",
    "\n",
    "# b) Prop‐level accuracy (micro average across all props)\n",
    "prop_acc = (\n",
    "    df\n",
    "    .groupby([\"model\", \"prompt\", \"dataset\"])\n",
    "    .sum()[[\"correct_props\", \"total_props\"]]\n",
    "    .assign(prop_accuracy=lambda x: x[\"correct_props\"] / x[\"total_props\"])\n",
    "    .reset_index()[[\"model\", \"prompt\", \"dataset\", \"prop_accuracy\"]]\n",
    ")\n",
    "\n",
    "# Merge both metrics\n",
    "accuracy = exact_acc.merge(prop_acc, on=[\"model\", \"prompt\", \"dataset\"])\n",
    "\n",
    "accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
